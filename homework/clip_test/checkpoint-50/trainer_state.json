{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.0005387872975506729,
  "eval_steps": 500,
  "global_step": 50,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 1.0775745951013459e-05,
      "grad_norm": 13.198349952697754,
      "learning_rate": 0.0005,
      "loss": 0.7656,
      "step": 1
    },
    {
      "epoch": 2.1551491902026918e-05,
      "grad_norm": 30.59808349609375,
      "learning_rate": 0.0004999461264949897,
      "loss": 0.8906,
      "step": 2
    },
    {
      "epoch": 3.2327237853040375e-05,
      "grad_norm": 8.830945014953613,
      "learning_rate": 0.0004998922529899795,
      "loss": 0.6641,
      "step": 3
    },
    {
      "epoch": 4.3102983804053835e-05,
      "grad_norm": 15.608803749084473,
      "learning_rate": 0.0004998383794849693,
      "loss": 0.832,
      "step": 4
    },
    {
      "epoch": 5.3878729755067296e-05,
      "grad_norm": 29.744976043701172,
      "learning_rate": 0.0004997845059799591,
      "loss": 0.8047,
      "step": 5
    },
    {
      "epoch": 6.465447570608075e-05,
      "grad_norm": 10.60838794708252,
      "learning_rate": 0.0004997306324749488,
      "loss": 0.75,
      "step": 6
    },
    {
      "epoch": 7.543022165709421e-05,
      "grad_norm": 35.20724105834961,
      "learning_rate": 0.0004996767589699386,
      "loss": 0.7578,
      "step": 7
    },
    {
      "epoch": 8.620596760810767e-05,
      "grad_norm": 19.87106704711914,
      "learning_rate": 0.0004996228854649284,
      "loss": 0.8281,
      "step": 8
    },
    {
      "epoch": 9.698171355912113e-05,
      "grad_norm": 20.34366798400879,
      "learning_rate": 0.0004995690119599181,
      "loss": 0.5938,
      "step": 9
    },
    {
      "epoch": 0.00010775745951013459,
      "grad_norm": 29.245084762573242,
      "learning_rate": 0.0004995151384549079,
      "loss": 0.8828,
      "step": 10
    },
    {
      "epoch": 0.00011853320546114805,
      "grad_norm": 7.865031719207764,
      "learning_rate": 0.0004994612649498976,
      "loss": 0.7812,
      "step": 11
    },
    {
      "epoch": 0.0001293089514121615,
      "grad_norm": 2.6460371017456055,
      "learning_rate": 0.0004994073914448874,
      "loss": 0.6719,
      "step": 12
    },
    {
      "epoch": 0.00014008469736317497,
      "grad_norm": 5.8618083000183105,
      "learning_rate": 0.0004993535179398772,
      "loss": 0.9414,
      "step": 13
    },
    {
      "epoch": 0.00015086044331418842,
      "grad_norm": 7.91680383682251,
      "learning_rate": 0.0004992996444348669,
      "loss": 0.5625,
      "step": 14
    },
    {
      "epoch": 0.0001616361892652019,
      "grad_norm": 9.336518287658691,
      "learning_rate": 0.0004992457709298567,
      "loss": 0.459,
      "step": 15
    },
    {
      "epoch": 0.00017241193521621534,
      "grad_norm": 1.0763304233551025,
      "learning_rate": 0.0004991918974248465,
      "loss": 0.7031,
      "step": 16
    },
    {
      "epoch": 0.0001831876811672288,
      "grad_norm": 2.730936050415039,
      "learning_rate": 0.0004991380239198363,
      "loss": 0.7344,
      "step": 17
    },
    {
      "epoch": 0.00019396342711824226,
      "grad_norm": 31.136938095092773,
      "learning_rate": 0.000499084150414826,
      "loss": 1.7266,
      "step": 18
    },
    {
      "epoch": 0.0002047391730692557,
      "grad_norm": 5.537958145141602,
      "learning_rate": 0.0004990302769098157,
      "loss": 0.6641,
      "step": 19
    },
    {
      "epoch": 0.00021551491902026918,
      "grad_norm": 4.0398030281066895,
      "learning_rate": 0.0004989764034048056,
      "loss": 0.7891,
      "step": 20
    },
    {
      "epoch": 0.00022629066497128263,
      "grad_norm": 1.3683346509933472,
      "learning_rate": 0.0004989225298997953,
      "loss": 0.6562,
      "step": 21
    },
    {
      "epoch": 0.0002370664109222961,
      "grad_norm": 5.772317886352539,
      "learning_rate": 0.0004988686563947851,
      "loss": 0.6914,
      "step": 22
    },
    {
      "epoch": 0.00024784215687330955,
      "grad_norm": 0.08241992443799973,
      "learning_rate": 0.0004988147828897748,
      "loss": 0.6914,
      "step": 23
    },
    {
      "epoch": 0.000258617902824323,
      "grad_norm": 6.027029991149902,
      "learning_rate": 0.0004987609093847645,
      "loss": 0.7656,
      "step": 24
    },
    {
      "epoch": 0.00026939364877533645,
      "grad_norm": 4.4590535163879395,
      "learning_rate": 0.0004987070358797544,
      "loss": 0.6875,
      "step": 25
    },
    {
      "epoch": 0.00028016939472634995,
      "grad_norm": 1.1538690328598022,
      "learning_rate": 0.0004986531623747441,
      "loss": 0.6797,
      "step": 26
    },
    {
      "epoch": 0.0002909451406773634,
      "grad_norm": 5.216460227966309,
      "learning_rate": 0.0004985992888697339,
      "loss": 0.7891,
      "step": 27
    },
    {
      "epoch": 0.00030172088662837684,
      "grad_norm": 1.995360255241394,
      "learning_rate": 0.0004985454153647236,
      "loss": 0.7188,
      "step": 28
    },
    {
      "epoch": 0.0003124966325793903,
      "grad_norm": 21.57132911682129,
      "learning_rate": 0.0004984915418597135,
      "loss": 0.9297,
      "step": 29
    },
    {
      "epoch": 0.0003232723785304038,
      "grad_norm": 25.58584213256836,
      "learning_rate": 0.0004984376683547032,
      "loss": 0.8281,
      "step": 30
    },
    {
      "epoch": 0.00033404812448141724,
      "grad_norm": 20.52146339416504,
      "learning_rate": 0.0004983837948496929,
      "loss": 0.5977,
      "step": 31
    },
    {
      "epoch": 0.0003448238704324307,
      "grad_norm": 12.76494312286377,
      "learning_rate": 0.0004983299213446827,
      "loss": 0.7109,
      "step": 32
    },
    {
      "epoch": 0.00035559961638344413,
      "grad_norm": 26.135082244873047,
      "learning_rate": 0.0004982760478396724,
      "loss": 0.8516,
      "step": 33
    },
    {
      "epoch": 0.0003663753623344576,
      "grad_norm": 28.682714462280273,
      "learning_rate": 0.0004982221743346623,
      "loss": 0.6016,
      "step": 34
    },
    {
      "epoch": 0.0003771511082854711,
      "grad_norm": 2.2847189903259277,
      "learning_rate": 0.000498168300829652,
      "loss": 0.6953,
      "step": 35
    },
    {
      "epoch": 0.0003879268542364845,
      "grad_norm": 16.44513511657715,
      "learning_rate": 0.0004981144273246417,
      "loss": 0.6875,
      "step": 36
    },
    {
      "epoch": 0.000398702600187498,
      "grad_norm": 18.166433334350586,
      "learning_rate": 0.0004980605538196315,
      "loss": 0.8125,
      "step": 37
    },
    {
      "epoch": 0.0004094783461385114,
      "grad_norm": 9.470080375671387,
      "learning_rate": 0.0004980066803146213,
      "loss": 0.7266,
      "step": 38
    },
    {
      "epoch": 0.0004202540920895249,
      "grad_norm": 11.783801078796387,
      "learning_rate": 0.0004979528068096111,
      "loss": 0.8477,
      "step": 39
    },
    {
      "epoch": 0.00043102983804053837,
      "grad_norm": 1.7076281309127808,
      "learning_rate": 0.0004978989333046008,
      "loss": 0.6875,
      "step": 40
    },
    {
      "epoch": 0.0004418055839915518,
      "grad_norm": 8.653051376342773,
      "learning_rate": 0.0004978450597995905,
      "loss": 0.7891,
      "step": 41
    },
    {
      "epoch": 0.00045258132994256526,
      "grad_norm": 0.2977256774902344,
      "learning_rate": 0.0004977911862945803,
      "loss": 0.6953,
      "step": 42
    },
    {
      "epoch": 0.0004633570758935787,
      "grad_norm": 2.041459083557129,
      "learning_rate": 0.0004977373127895701,
      "loss": 0.7031,
      "step": 43
    },
    {
      "epoch": 0.0004741328218445922,
      "grad_norm": 1.140875220298767,
      "learning_rate": 0.0004976834392845599,
      "loss": 0.6875,
      "step": 44
    },
    {
      "epoch": 0.00048490856779560566,
      "grad_norm": 2.372746706008911,
      "learning_rate": 0.0004976295657795497,
      "loss": 0.7227,
      "step": 45
    },
    {
      "epoch": 0.0004956843137466191,
      "grad_norm": 6.523120880126953,
      "learning_rate": 0.0004975756922745394,
      "loss": 0.7617,
      "step": 46
    },
    {
      "epoch": 0.0005064600596976326,
      "grad_norm": 25.84351921081543,
      "learning_rate": 0.0004975218187695292,
      "loss": 0.9336,
      "step": 47
    },
    {
      "epoch": 0.000517235805648646,
      "grad_norm": 3.7729389667510986,
      "learning_rate": 0.0004974679452645189,
      "loss": 0.8711,
      "step": 48
    },
    {
      "epoch": 0.0005280115515996595,
      "grad_norm": 3.627300977706909,
      "learning_rate": 0.0004974140717595087,
      "loss": 0.7383,
      "step": 49
    },
    {
      "epoch": 0.0005387872975506729,
      "grad_norm": 1.7713128328323364,
      "learning_rate": 0.0004973601982544985,
      "loss": 0.6992,
      "step": 50
    }
  ],
  "logging_steps": 1,
  "max_steps": 9281,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 50,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
